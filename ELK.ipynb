{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('./Apache-20220324.log','r') as f:\n",
    "    content = f.readlines()\n",
    "with open('./Apache-20220325.log','r') as f2:\n",
    "    content2 = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ip                 time hour day  status\n",
      "0        223.140.18.62  24/03/2022:06:25:07   06  24     200\n",
      "1        223.140.18.62  24/03/2022:06:25:10   06  24     200\n",
      "2        223.140.18.62  24/03/2022:06:25:10   06  24     200\n",
      "3        223.140.18.62  24/03/2022:06:25:10   06  24     200\n",
      "4        223.140.18.62  24/03/2022:06:25:10   06  24     200\n",
      "...                ...                  ...  ...  ..     ...\n",
      "182524  60.248.123.153  25/03/2022:20:50:10   20  25     200\n",
      "182525  60.248.123.153  25/03/2022:20:50:10   20  25     200\n",
      "182526  60.248.123.153  25/03/2022:20:50:10   20  25     200\n",
      "182527  60.248.123.153  25/03/2022:20:50:10   20  25     200\n",
      "182528             ::1  25/03/2022:20:50:12   20  25     200\n",
      "\n",
      "[182529 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for line in content:\n",
    "  ip = line.split(\" - -\")[0]\n",
    "  time = line.split(\"[\")[1].split(\" +0800\")[0]\n",
    "  hour = time.split(\":\")[1].split(\":\")[0]\n",
    "  day = time.split(\"/\")[0]\n",
    "  status = int(line.split(\"\\\" \")[2].split(\" \")[0])\n",
    "  ls.append({\"ip\":ip,\"time\":time,\"hour\":hour,\"day\":day,\"status\":status})\n",
    "\n",
    "for line2 in content2:\n",
    "  ip2 = line2.split(\" - -\")[0]\n",
    "  time2 = line2.split(\"[\")[1].split(\" +0800\")[0]\n",
    "  hour2 = time2.split(\":\")[1].split(\":\")[0]\n",
    "  day2 = time2.split(\"/\")[0]\n",
    "  status2 = int(line2.split(\"\\\" \")[2].split(\" \")[0])\n",
    "  ls.append({\"ip\":ip2,\"time\":time2,\"hour\":hour2,\"day\":day2,\"status\":status2})\n",
    "\n",
    "# 將資料轉換為df,方便進行後續分析\n",
    "df = pd.DataFrame(ls)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\1356870853.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  hourgroup = df1[df1['day']=='24'][df1['status']>=404][df1['status']<=500].groupby('hour').count()\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\1356870853.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  hourgroup2 = df1[df1['day']=='25'][df1['status']>=404][df1['status']<=500].groupby('hour').count()\n"
     ]
    }
   ],
   "source": [
    "# 1. 計算每小時404-500數量\n",
    "df1 = df.copy()\n",
    "\n",
    "# 分別針對24號及25號的資料,將status為404-500的部分萃取出來,依照小時分組並計數\n",
    "hourgroup = df1[df1['day']=='24'][df1['status']>=404][df1['status']<=500].groupby('hour').count()\n",
    "hourgroup_count = hourgroup[['status']]\n",
    "hourgroup2 = df1[df1['day']=='25'][df1['status']>=404][df1['status']<=500].groupby('hour').count()\n",
    "hourgroup_count2 = hourgroup2[['status']]\n",
    "df2 = pd.concat([hourgroup_count,hourgroup_count2],keys=['24','25'])\n",
    "df2\n",
    "\n",
    "# 將df存成CSV檔\n",
    "df2.to_csv('./csv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\3661239977.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  IPgroup = df1[df1['day']=='24'][df1['status']>=404][df1['status']<=500].groupby('ip').count()\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\3661239977.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  IPgroup2 = df1[df1['day']=='25'][df1['status']>=404][df1['status']<=500].groupby('ip').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               diff\n",
      "                   \n",
      "ip                 \n",
      "1.160.215.41  -0.75\n",
      "1.162.22.24    0.00\n",
      "1.168.195.82   0.00\n",
      "1.169.163.199  0.00\n",
      "1.169.2.47     0.00\n",
      "...             ...\n",
      "66.249.64.114  0.00\n",
      "66.249.64.116  0.00\n",
      "66.249.64.118  0.00\n",
      "66.249.64.147  0.00\n",
      "66.249.64.58   0.00\n",
      "\n",
      "[454 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2. 同IP觸發404-500今天與昨天的差異比例((今天值-昨天值)/昨天值)\n",
    "\n",
    "# 分別針對24號及25號的資料,將status為404-500的部分萃取出來,依照IP分組並計數\n",
    "IPgroup = df1[df1['day']=='24'][df1['status']>=404][df1['status']<=500].groupby('ip').count()\n",
    "IPgroup2 = df1[df1['day']=='25'][df1['status']>=404][df1['status']<=500].groupby('ip').count()\n",
    "df3 = pd.concat([IPgroup,IPgroup2],axis=1,keys=['24','25'])\n",
    "\n",
    "# 逐行計算每個IP,觸發404-500今天與昨天的差異比例\n",
    "data = []\n",
    "for row in range(df3.shape[0]):\n",
    "  diff = (df3.iloc[row]['25']['status'] - df3.iloc[row]['24']['status'])/ (df3.iloc[row]['24']['status'])\n",
    "  data.append(diff)\n",
    "\n",
    "# 將計算結果生成一個新的欄位\n",
    "df3['diff'] = data\n",
    "df3 = df3.drop(columns=['24','25'])\n",
    "df3 = df3.fillna(0)\n",
    "print(df3)\n",
    "\n",
    "# 將df存成CSV檔\n",
    "df3.to_csv('./csv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\14819634.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  IPgroup3 = df1[df1['day']=='24'][df1['status']>=200][df1['status']<=299].groupby('ip').count()\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\14819634.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  IPgroup4 = df1[df1['day']=='25'][df1['status']>=200][df1['status']<=299].groupby('ip').count()\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\14819634.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff2 = ((df4.iloc[row2]['25-404-500']['status'] - df4.iloc[row2]['24-404-500']['status'])/(df4.iloc[row2]['24-404-500']['status'])) / ((df4.iloc[row2]['25-200-299']['status'] - df4.iloc[row2]['24-200-299']['status'])/(df4.iloc[row2]['24-200-299']['status']))\n"
     ]
    }
   ],
   "source": [
    "# 3. 同IP觸發404-500今天與昨天的差異比例,與200-299今天與昨天的差異比例 (404-500差異比例)/(200-299差異比例) \n",
    "\n",
    "# 分別針對24號及25號的資料,將status為200-299的部分萃取出來,依照IP分組並計數\n",
    "IPgroup3 = df1[df1['day']=='24'][df1['status']>=200][df1['status']<=299].groupby('ip').count()\n",
    "IPgroup4 = df1[df1['day']=='25'][df1['status']>=200][df1['status']<=299].groupby('ip').count()\n",
    "\n",
    "# 把24、25號,status為200-299、404-500的內容都整併起來看\n",
    "df4 = pd.concat([IPgroup,IPgroup2,IPgroup3,IPgroup4],axis=1,keys=['24-404-500','25-404-500','24-200-299','25-200-299'])\n",
    "\n",
    "# 逐行計算每個IP的差異比例\n",
    "data2 = []\n",
    "for row2 in range(df4.shape[0]):\n",
    "  diff2 = ((df4.iloc[row2]['25-404-500']['status'] - df4.iloc[row2]['24-404-500']['status'])/(df4.iloc[row2]['24-404-500']['status'])) / ((df4.iloc[row2]['25-200-299']['status'] - df4.iloc[row2]['24-200-299']['status'])/(df4.iloc[row2]['24-200-299']['status']))\n",
    "  data2.append(diff2)\n",
    "\n",
    "# 將計算結果生成一個新的欄位\n",
    "df4['diff2'] = data2\n",
    "df4 = df4.drop(columns=['24-404-500','25-404-500','24-200-299','25-200-299'])\n",
    "df4 = df4.fillna(0)\n",
    "df4\n",
    "\n",
    "# 將df存成CSV檔\n",
    "df4.to_csv('./csv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_13428\\1345020262.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  daygroup = df1[df1['status']>=404][df1['status']<=500].groupby('day').count()\n"
     ]
    }
   ],
   "source": [
    "# 4. 統計觸發404-500的IP(天) \n",
    "\n",
    "# 將status為404-500的IP部分萃取出來,依照天分組並計數\n",
    "daygroup = df1[df1['status']>=404][df1['status']<=500].groupby('day').count()\n",
    "daygroup_count = daygroup[['ip']]\n",
    "daygroup_count\n",
    "\n",
    "# 將df存成CSV檔\n",
    "daygroup_count.to_csv('./csv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELK - 將4個csv寫入Elasticsearch\n",
    "# 第一題\n",
    "input {\n",
    "        file {\n",
    "                path => \"./csv1.csv\"\n",
    "                start_position => \"beginning\"\n",
    "                sincedb_path => \"/dev/null\"\n",
    "        }\n",
    "}\n",
    "\n",
    "filter {\n",
    "                csv {\n",
    "                        separator => \",\"\n",
    "                        columns => [\"Hour\",\"StatusCount\"]\n",
    "                }\n",
    "\n",
    "                mutate {\n",
    "                        convert => { \"Hour\" => \"integer\" }\n",
    "                        convert => { \"StatusCount\" => \"integer\" }\n",
    "                }      \n",
    "}\n",
    "\n",
    "output {\n",
    "                elasticsearch {\n",
    "                        hosts => [\"0.0.0.0:9200\"]\n",
    "                        index => \"logstash-hourcount\"\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二題\n",
    "\n",
    "input {\n",
    "        file {\n",
    "                path => \"./csv2.csv\"\n",
    "                start_position => \"beginning\"\n",
    "                sincedb_path => \"/dev/null\"\n",
    "        }\n",
    "}\n",
    "\n",
    "filter {\n",
    "                csv {\n",
    "                        separator => \",\"\n",
    "                        columns => [\"IP\",\"Diff\"]\n",
    "                }\n",
    "\n",
    "                mutate {\n",
    "                        convert => { \"Diff\" => \"integer\" }\n",
    "                }\n",
    "}\n",
    "\n",
    "output {\n",
    "                elasticsearch {\n",
    "                        hosts => [\"0.0.0.0:9200\"]\n",
    "                        index => \"logstash-45diff\"\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三題\n",
    "\n",
    "input {\n",
    "        file {\n",
    "                path => \"./csv3.csv\"\n",
    "                start_position => \"beginning\"\n",
    "                sincedb_path => \"/dev/null\"\n",
    "        }\n",
    "}\n",
    "\n",
    "filter {\n",
    "                csv {\n",
    "                        separator => \",\"\n",
    "                        columns => [\"IP\",\"Diff\"]\n",
    "                }\n",
    "\n",
    "                mutate {\n",
    "                        convert => { \"Diff\" => \"integer\" }\n",
    "                }\n",
    "}\n",
    "\n",
    "output {\n",
    "                elasticsearch {\n",
    "                        hosts => [\"0.0.0.0:9200\"]\n",
    "                        index => \"logstash-2345diff\"\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四題\n",
    "\n",
    "input {\n",
    "        file {\n",
    "                path => \"./csv4.csv\"\n",
    "                start_position => \"beginning\"\n",
    "                sincedb_path => \"/dev/null\"\n",
    "        }\n",
    "}\n",
    "\n",
    "filter {\n",
    "                csv {\n",
    "                        separator => \",\"\n",
    "                        columns => [\"Day\",\"IP\"]\n",
    "                }\n",
    "\n",
    "                mutate {\n",
    "                        convert => { \"Day\" => \"integer\" }\n",
    "                }\n",
    "}\n",
    "\n",
    "output {\n",
    "                elasticsearch {\n",
    "                        hosts => [\"0.0.0.0:9200\"]\n",
    "                        index => \"logstash-dayipcount\"\n",
    "                }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7907e722ef99856ec832da1f8c6d21bd44b229b831a16ab039175ec7eaa3a64c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
